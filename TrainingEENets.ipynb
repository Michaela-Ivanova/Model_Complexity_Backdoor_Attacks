{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training EENet exit heads"
      ],
      "metadata": {
        "id": "vxQmoj47olLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook provides code for training EENet [1] exit heads for clean and poisoned Resnet models. For each attack, the code would load the saved weights from the previously finetuned models on Oxfordpets with/without attacks and freezes the backbone model in order to train the exit heads from scratch."
      ],
      "metadata": {
        "id": "DRpXmq3Fo85j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYqX_dSFZEz5",
        "outputId": "c10218bd-a249-4871-fcd0-66b998095ba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from copy import deepcopy\n",
        "\n",
        "from PIL import Image\n"
      ],
      "metadata": {
        "id": "x0B8K_twWYld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING BADNET EENETS"
      ],
      "metadata": {
        "id": "q0euzzXhexsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        assert base_model in [\n",
        "            'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "            'wide_resnet50_2', 'wide_resnet101_2'\n",
        "        ], \"Unsupported model.\"\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.exit1 = None\n",
        "        self.exit2 = None\n",
        "        self.exit3 = None\n",
        "        self.exit4 = None\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4); pooled = torch.flatten(pooled, 1)\n",
        "        final_out = self.softmax(self.final_fc(pooled)); preds.append(final_out)\n",
        "        return preds\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_CLASS = 0\n",
        "MODEL_LIST = [\n",
        "    'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "    'wide_resnet50_2', 'wide_resnet101_2'\n",
        "]\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Badnet_ExitHeads'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Trigger function (same as existing)\n",
        "def add_trigger(image, trigger_size=5, trigger_color=(1, 1, 1)):\n",
        "    img = image.clone()\n",
        "    _, h, w = img.shape\n",
        "    img[:, h - trigger_size:h, w - trigger_size:w] = torch.tensor(trigger_color).view(3, 1, 1)\n",
        "    return img\n",
        "\n",
        "# Poison dataset\n",
        "def poison_dataset(dataset, fraction=0.1, target_class=0):\n",
        "    from copy import deepcopy\n",
        "    import random\n",
        "    poisoned = []\n",
        "    dataset = deepcopy(dataset)\n",
        "    n_total = len(dataset)\n",
        "    n_poison = int(n_total * fraction)\n",
        "    indices = random.sample(range(n_total), n_poison)\n",
        "    for i, (x, y) in enumerate(dataset):\n",
        "        if i in indices:\n",
        "            x = add_trigger(x)\n",
        "            y = target_class\n",
        "        poisoned.append((x, y))\n",
        "    return poisoned\n",
        "\n",
        "# Main training loop\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"Training exit heads for {model_name}...\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = EEResNet(base_model=model_name).to(device)\n",
        "\n",
        "    # Load frozen backbone\n",
        "    backbone_path = f\"/content/drive/MyDrive/Colab Notebooks/BadNetModels/{model_name}_badnet.pth\"\n",
        "    state_dict = torch.load(backbone_path, map_location=device)\n",
        "    state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
        "    model.backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    # Freeze backbone\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    train_dataset = OxfordIIITPet(root='.', split='trainval', target_types='category', transform=transform, download=True)\n",
        "    poisoned_dataset = poison_dataset(train_dataset, fraction=0.1, target_class=TARGET_CLASS)\n",
        "    train_loader = DataLoader(poisoned_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train only exit heads and final FC\n",
        "    exit_params = list(model.exit1.parameters()) + list(model.exit2.parameters()) + \\\n",
        "                  list(model.exit3.parameters()) + list(model.exit4.parameters()) + \\\n",
        "                  list(model.final_fc.parameters())\n",
        "    optimizer = optim.Adam(exit_params, lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = sum(criterion(out, targets) for out in outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = outputs[-1].max(1)\n",
        "            correct += preds.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "        print(f\"{model_name} | Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss / total:.4f} | Acc: {100 * correct / total:.2f}%\")\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\"))\n",
        "    print(f\"Saved model: {model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vt9HoGSvZJu5",
        "outputId": "cf29989b-223f-47be-d3e3-ba9c1f1e5338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training exit heads for resnet18...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:46<00:00, 17.0MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:02<00:00, 8.60MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet18 | Epoch 1/10 | Loss: 17.9676 | Acc: 14.84%\n",
            "resnet18 | Epoch 2/10 | Loss: 17.5743 | Acc: 42.26%\n",
            "resnet18 | Epoch 3/10 | Loss: 16.9339 | Acc: 78.72%\n",
            "resnet18 | Epoch 4/10 | Loss: 16.5948 | Acc: 84.51%\n",
            "resnet18 | Epoch 5/10 | Loss: 16.4955 | Acc: 84.86%\n",
            "resnet18 | Epoch 6/10 | Loss: 16.4386 | Acc: 86.98%\n",
            "resnet18 | Epoch 7/10 | Loss: 16.3858 | Acc: 89.29%\n",
            "resnet18 | Epoch 8/10 | Loss: 16.3554 | Acc: 89.40%\n",
            "resnet18 | Epoch 9/10 | Loss: 16.3236 | Acc: 89.89%\n",
            "resnet18 | Epoch 10/10 | Loss: 16.2753 | Acc: 92.20%\n",
            "Saved model: resnet18\n",
            "Training exit heads for resnet34...\n",
            "resnet34 | Epoch 1/10 | Loss: 17.9365 | Acc: 15.22%\n",
            "resnet34 | Epoch 2/10 | Loss: 17.3922 | Acc: 60.95%\n",
            "resnet34 | Epoch 3/10 | Loss: 16.6843 | Acc: 91.63%\n",
            "resnet34 | Epoch 4/10 | Loss: 16.4305 | Acc: 92.20%\n",
            "resnet34 | Epoch 5/10 | Loss: 16.3536 | Acc: 92.42%\n",
            "resnet34 | Epoch 6/10 | Loss: 16.3136 | Acc: 92.83%\n",
            "resnet34 | Epoch 7/10 | Loss: 16.2636 | Acc: 94.73%\n",
            "resnet34 | Epoch 8/10 | Loss: 16.2258 | Acc: 94.92%\n",
            "resnet34 | Epoch 9/10 | Loss: 16.1858 | Acc: 95.05%\n",
            "resnet34 | Epoch 10/10 | Loss: 16.1399 | Acc: 97.07%\n",
            "Saved model: resnet34\n",
            "Training exit heads for resnet50...\n",
            "resnet50 | Epoch 1/10 | Loss: 17.7137 | Acc: 29.13%\n",
            "resnet50 | Epoch 2/10 | Loss: 16.6336 | Acc: 87.15%\n",
            "resnet50 | Epoch 3/10 | Loss: 16.3279 | Acc: 95.16%\n",
            "resnet50 | Epoch 4/10 | Loss: 16.2689 | Acc: 95.76%\n",
            "resnet50 | Epoch 5/10 | Loss: 16.2312 | Acc: 96.36%\n",
            "resnet50 | Epoch 6/10 | Loss: 16.1847 | Acc: 96.79%\n",
            "resnet50 | Epoch 7/10 | Loss: 16.1404 | Acc: 96.71%\n",
            "resnet50 | Epoch 8/10 | Loss: 16.0993 | Acc: 96.68%\n",
            "resnet50 | Epoch 9/10 | Loss: 16.0665 | Acc: 96.60%\n",
            "resnet50 | Epoch 10/10 | Loss: 16.0472 | Acc: 96.93%\n",
            "Saved model: resnet50\n",
            "Training exit heads for resnet101...\n",
            "resnet101 | Epoch 1/10 | Loss: 17.7260 | Acc: 45.05%\n",
            "resnet101 | Epoch 2/10 | Loss: 16.6925 | Acc: 92.04%\n",
            "resnet101 | Epoch 3/10 | Loss: 16.3372 | Acc: 95.57%\n",
            "resnet101 | Epoch 4/10 | Loss: 16.2376 | Acc: 98.02%\n",
            "resnet101 | Epoch 5/10 | Loss: 16.1707 | Acc: 97.96%\n",
            "resnet101 | Epoch 6/10 | Loss: 16.1144 | Acc: 97.85%\n",
            "resnet101 | Epoch 7/10 | Loss: 16.0715 | Acc: 97.88%\n",
            "resnet101 | Epoch 8/10 | Loss: 16.0440 | Acc: 97.99%\n",
            "resnet101 | Epoch 9/10 | Loss: 16.0209 | Acc: 98.10%\n",
            "resnet101 | Epoch 10/10 | Loss: 16.0036 | Acc: 98.04%\n",
            "Saved model: resnet101\n",
            "Training exit heads for resnet152...\n",
            "resnet152 | Epoch 1/10 | Loss: 17.6446 | Acc: 65.98%\n",
            "resnet152 | Epoch 2/10 | Loss: 16.4558 | Acc: 97.91%\n",
            "resnet152 | Epoch 3/10 | Loss: 16.2238 | Acc: 98.21%\n",
            "resnet152 | Epoch 4/10 | Loss: 16.1569 | Acc: 98.12%\n",
            "resnet152 | Epoch 5/10 | Loss: 16.0943 | Acc: 98.18%\n",
            "resnet152 | Epoch 6/10 | Loss: 16.0506 | Acc: 98.23%\n",
            "resnet152 | Epoch 7/10 | Loss: 16.0286 | Acc: 98.34%\n",
            "resnet152 | Epoch 8/10 | Loss: 16.0045 | Acc: 98.40%\n",
            "resnet152 | Epoch 9/10 | Loss: 15.9893 | Acc: 98.29%\n",
            "resnet152 | Epoch 10/10 | Loss: 15.9771 | Acc: 98.32%\n",
            "Saved model: resnet152\n",
            "Training exit heads for wide_resnet50_2...\n",
            "wide_resnet50_2 | Epoch 1/10 | Loss: 17.8234 | Acc: 34.27%\n",
            "wide_resnet50_2 | Epoch 2/10 | Loss: 16.7712 | Acc: 94.81%\n",
            "wide_resnet50_2 | Epoch 3/10 | Loss: 16.3596 | Acc: 97.42%\n",
            "wide_resnet50_2 | Epoch 4/10 | Loss: 16.2739 | Acc: 97.58%\n",
            "wide_resnet50_2 | Epoch 5/10 | Loss: 16.2208 | Acc: 97.39%\n",
            "wide_resnet50_2 | Epoch 6/10 | Loss: 16.1704 | Acc: 97.26%\n",
            "wide_resnet50_2 | Epoch 7/10 | Loss: 16.1126 | Acc: 97.50%\n",
            "wide_resnet50_2 | Epoch 8/10 | Loss: 16.0710 | Acc: 97.55%\n",
            "wide_resnet50_2 | Epoch 9/10 | Loss: 16.0397 | Acc: 97.72%\n",
            "wide_resnet50_2 | Epoch 10/10 | Loss: 16.0195 | Acc: 97.64%\n",
            "Saved model: wide_resnet50_2\n",
            "Training exit heads for wide_resnet101_2...\n",
            "wide_resnet101_2 | Epoch 1/10 | Loss: 17.7267 | Acc: 55.71%\n",
            "wide_resnet101_2 | Epoch 2/10 | Loss: 16.6121 | Acc: 94.08%\n",
            "wide_resnet101_2 | Epoch 3/10 | Loss: 16.2797 | Acc: 97.45%\n",
            "wide_resnet101_2 | Epoch 4/10 | Loss: 16.1953 | Acc: 97.39%\n",
            "wide_resnet101_2 | Epoch 5/10 | Loss: 16.1395 | Acc: 97.39%\n",
            "wide_resnet101_2 | Epoch 6/10 | Loss: 16.0980 | Acc: 97.64%\n",
            "wide_resnet101_2 | Epoch 7/10 | Loss: 16.0635 | Acc: 97.50%\n",
            "wide_resnet101_2 | Epoch 8/10 | Loss: 16.0345 | Acc: 97.45%\n",
            "wide_resnet101_2 | Epoch 9/10 | Loss: 16.0173 | Acc: 97.39%\n",
            "wide_resnet101_2 | Epoch 10/10 | Loss: 16.0033 | Acc: 97.53%\n",
            "Saved model: wide_resnet101_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting accuracy and ASR for every exit"
      ],
      "metadata": {
        "id": "E5GQ3nlbUw3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        assert base_model in [\n",
        "            'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "            'wide_resnet50_2', 'wide_resnet101_2'\n",
        "        ], \"Unsupported model.\"\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.exit1 = None\n",
        "        self.exit2 = None\n",
        "        self.exit3 = None\n",
        "        self.exit4 = None\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4); pooled = torch.flatten(pooled, 1)\n",
        "        final_out = self.softmax(self.final_fc(pooled)); preds.append(final_out)\n",
        "        return preds\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 64\n",
        "TARGET_CLASS = 0\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Badnet_ExitHeads'\n",
        "MODEL_LIST = [\n",
        "    'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "    'wide_resnet50_2', 'wide_resnet101_2'\n",
        "]\n",
        "\n",
        "# Trigger function\n",
        "def add_trigger(image, trigger_size=5, trigger_color=(1, 1, 1)):\n",
        "    img = image.clone()\n",
        "    _, h, w = img.shape\n",
        "    img[:, h - trigger_size:h, w - trigger_size:w] = torch.tensor(trigger_color).view(3, 1, 1)\n",
        "    return img\n",
        "\n",
        "# Load test datasets\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_dataset = OxfordIIITPet(root='.', split='test', target_types='category', transform=transform, download=True)\n",
        "triggered_dataset = [(add_trigger(img), TARGET_CLASS) for img, _ in test_dataset]\n",
        "\n",
        "clean_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "triggered_loader = DataLoader(triggered_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Evaluate each model\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "    model = EEResNet(base_model=model_name).to(device)\n",
        "    path = os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\")\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    clean_correct = [0] * 5\n",
        "    asr_correct = [0] * 5\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in clean_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                preds = out.argmax(dim=1)\n",
        "                clean_correct[i] += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        for imgs, _ in triggered_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                preds = out.argmax(dim=1)\n",
        "                asr_correct[i] += (preds == TARGET_CLASS).sum().item()\n",
        "\n",
        "    for i in range(5):\n",
        "        acc = 100 * clean_correct[i] / total\n",
        "        asr = 100 * asr_correct[i] / total\n",
        "        results.append({\n",
        "            'Model': model_name,\n",
        "            'Exit': f'Exit {i+1}',\n",
        "            'Clean Accuracy': acc,\n",
        "            'ASR': asr\n",
        "        })\n",
        "        print(f\"Exit {i+1}: Clean Acc = {acc:.2f}%, ASR = {asr:.2f}%\")\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv(os.path.join(SAVE_DIR, 'badnet_exit_metrics.csv'), index=False)\n",
        "print(\"Saved per-exit accuracy and ASR.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhdqoatsUwV9",
        "outputId": "cbe39187-3ffb-4f88-9041-5b83ac62da94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:44<00:00, 17.9MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:02<00:00, 8.52MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating resnet18...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 82.34%, ASR = 94.88%\n",
            "Exit 5: Clean Acc = 83.40%, ASR = 94.79%\n",
            "\n",
            "Evaluating resnet34...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 85.42%, ASR = 95.94%\n",
            "Exit 5: Clean Acc = 90.13%, ASR = 95.75%\n",
            "\n",
            "Evaluating resnet50...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 91.28%, ASR = 96.16%\n",
            "Exit 5: Clean Acc = 91.36%, ASR = 96.16%\n",
            "\n",
            "Evaluating resnet101...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 84.76%, ASR = 96.65%\n",
            "Exit 5: Clean Acc = 85.04%, ASR = 96.57%\n",
            "\n",
            "Evaluating resnet152...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 90.19%, ASR = 95.28%\n",
            "Exit 5: Clean Acc = 90.22%, ASR = 95.28%\n",
            "\n",
            "Evaluating wide_resnet50_2...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 86.37%, ASR = 96.16%\n",
            "Exit 5: Clean Acc = 86.29%, ASR = 96.08%\n",
            "\n",
            "Evaluating wide_resnet101_2...\n",
            "Exit 1: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 2: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 3: Clean Acc = 2.67%, ASR = 100.00%\n",
            "Exit 4: Clean Acc = 87.22%, ASR = 95.12%\n",
            "Exit 5: Clean Acc = 87.22%, ASR = 95.15%\n",
            "Saved per-exit accuracy and ASR.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING CLEAN EENETS"
      ],
      "metadata": {
        "id": "Q0DRoS0Xe03t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        assert base_model in [\n",
        "            'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "            'wide_resnet50_2', 'wide_resnet101_2'\n",
        "        ], \"Unsupported model.\"\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.exit1 = None\n",
        "        self.exit2 = None\n",
        "        self.exit3 = None\n",
        "        self.exit4 = None\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4); pooled = torch.flatten(pooled, 1)\n",
        "        final_out = self.softmax(self.final_fc(pooled)); preds.append(final_out)\n",
        "        return preds\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_CLASS = 0\n",
        "\n",
        "MODEL_LIST = [ 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152','wide_resnet50_2', 'wide_resnet101_2']\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Clean_ExitHeads'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Trigger function (same as existing)\n",
        "#def add_trigger(image, trigger_size=5, trigger_color=(1, 1, 1)):\n",
        "    #img = image.clone()\n",
        "    #_, h, w = img.shape\n",
        "    #img[:, h - trigger_size:h, w - trigger_size:w] = torch.tensor(trigger_color).view(3, 1, 1)\n",
        "    #return img\n",
        "\n",
        "\n",
        "# Main training loop\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"Training exit heads for {model_name}...\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = EEResNet(base_model=model_name).to(device)\n",
        "\n",
        "    # Load frozen backbone\n",
        "    backbone_path = f\"/content/drive/MyDrive/Colab Notebooks/TrainedModels/{model_name}_oxfordpets_clean.pth\"\n",
        "    state_dict = torch.load(backbone_path, map_location=device)\n",
        "    state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
        "    model.backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    # Freeze backbone\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Data\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    train_dataset = OxfordIIITPet(root='.', split='trainval', target_types='category', transform=transform, download=True)\n",
        "    train_data = train_dataset\n",
        "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Train only exit heads and final FC\n",
        "    exit_params = list(model.exit1.parameters()) + list(model.exit2.parameters()) + \\\n",
        "                  list(model.exit3.parameters()) + list(model.exit4.parameters()) + \\\n",
        "                  list(model.final_fc.parameters())\n",
        "    optimizer = optim.Adam(exit_params, lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = sum(criterion(out, targets) for out in outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = outputs[-1].max(1)\n",
        "            correct += preds.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "        print(f\"{model_name} | Epoch {epoch+1}/{EPOCHS} | Loss: {total_loss / total:.4f} | Acc: {100 * correct / total:.2f}%\")\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\"))\n",
        "    print(f\"Saved model: {model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HPR9nuhbqHO",
        "outputId": "494cfe06-ba18-46fa-b312-9ac5e68a7f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training exit heads for wide_resnet50_2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:21<00:00, 36.8MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:01<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wide_resnet50_2 | Epoch 1/30 | Loss: 17.8780 | Acc: 46.60%\n",
            "wide_resnet50_2 | Epoch 2/30 | Loss: 17.0151 | Acc: 89.21%\n",
            "wide_resnet50_2 | Epoch 3/30 | Loss: 16.5219 | Acc: 96.47%\n",
            "wide_resnet50_2 | Epoch 4/30 | Loss: 16.3946 | Acc: 96.93%\n",
            "wide_resnet50_2 | Epoch 5/30 | Loss: 16.3463 | Acc: 96.93%\n",
            "wide_resnet50_2 | Epoch 6/30 | Loss: 16.3142 | Acc: 97.15%\n",
            "wide_resnet50_2 | Epoch 7/30 | Loss: 16.2970 | Acc: 97.04%\n",
            "wide_resnet50_2 | Epoch 8/30 | Loss: 16.2827 | Acc: 97.07%\n",
            "wide_resnet50_2 | Epoch 9/30 | Loss: 16.2693 | Acc: 97.26%\n",
            "wide_resnet50_2 | Epoch 10/30 | Loss: 16.2616 | Acc: 97.23%\n",
            "wide_resnet50_2 | Epoch 11/30 | Loss: 16.2539 | Acc: 97.58%\n",
            "wide_resnet50_2 | Epoch 12/30 | Loss: 16.2562 | Acc: 97.23%\n",
            "wide_resnet50_2 | Epoch 13/30 | Loss: 16.2446 | Acc: 97.45%\n",
            "wide_resnet50_2 | Epoch 14/30 | Loss: 16.2370 | Acc: 97.93%\n",
            "wide_resnet50_2 | Epoch 15/30 | Loss: 16.2374 | Acc: 97.55%\n",
            "wide_resnet50_2 | Epoch 16/30 | Loss: 16.2346 | Acc: 97.23%\n",
            "wide_resnet50_2 | Epoch 17/30 | Loss: 16.2276 | Acc: 97.39%\n",
            "wide_resnet50_2 | Epoch 18/30 | Loss: 16.2251 | Acc: 97.55%\n",
            "wide_resnet50_2 | Epoch 19/30 | Loss: 16.2217 | Acc: 97.85%\n",
            "wide_resnet50_2 | Epoch 20/30 | Loss: 16.2250 | Acc: 97.42%\n",
            "wide_resnet50_2 | Epoch 21/30 | Loss: 16.2162 | Acc: 97.58%\n",
            "wide_resnet50_2 | Epoch 22/30 | Loss: 16.2196 | Acc: 97.50%\n",
            "wide_resnet50_2 | Epoch 23/30 | Loss: 16.2130 | Acc: 97.58%\n",
            "wide_resnet50_2 | Epoch 24/30 | Loss: 16.2163 | Acc: 97.64%\n",
            "wide_resnet50_2 | Epoch 25/30 | Loss: 16.2127 | Acc: 97.80%\n",
            "wide_resnet50_2 | Epoch 26/30 | Loss: 16.2089 | Acc: 97.91%\n",
            "wide_resnet50_2 | Epoch 27/30 | Loss: 16.2106 | Acc: 97.72%\n",
            "wide_resnet50_2 | Epoch 28/30 | Loss: 16.2072 | Acc: 97.72%\n",
            "wide_resnet50_2 | Epoch 29/30 | Loss: 16.2036 | Acc: 97.77%\n",
            "wide_resnet50_2 | Epoch 30/30 | Loss: 16.2026 | Acc: 97.80%\n",
            "Saved model: wide_resnet50_2\n",
            "Training exit heads for wide_resnet101_2...\n",
            "wide_resnet101_2 | Epoch 1/30 | Loss: 17.8771 | Acc: 57.91%\n",
            "wide_resnet101_2 | Epoch 2/30 | Loss: 16.9990 | Acc: 91.11%\n",
            "wide_resnet101_2 | Epoch 3/30 | Loss: 16.5177 | Acc: 96.36%\n",
            "wide_resnet101_2 | Epoch 4/30 | Loss: 16.3981 | Acc: 96.68%\n",
            "wide_resnet101_2 | Epoch 5/30 | Loss: 16.3499 | Acc: 96.77%\n",
            "wide_resnet101_2 | Epoch 6/30 | Loss: 16.3233 | Acc: 96.93%\n",
            "wide_resnet101_2 | Epoch 7/30 | Loss: 16.3033 | Acc: 97.04%\n",
            "wide_resnet101_2 | Epoch 8/30 | Loss: 16.2867 | Acc: 96.85%\n",
            "wide_resnet101_2 | Epoch 9/30 | Loss: 16.2775 | Acc: 96.74%\n",
            "wide_resnet101_2 | Epoch 10/30 | Loss: 16.2660 | Acc: 97.20%\n",
            "wide_resnet101_2 | Epoch 11/30 | Loss: 16.2604 | Acc: 96.90%\n",
            "wide_resnet101_2 | Epoch 12/30 | Loss: 16.2591 | Acc: 96.79%\n",
            "wide_resnet101_2 | Epoch 13/30 | Loss: 16.2493 | Acc: 97.15%\n",
            "wide_resnet101_2 | Epoch 14/30 | Loss: 16.2446 | Acc: 97.23%\n",
            "wide_resnet101_2 | Epoch 15/30 | Loss: 16.2445 | Acc: 97.26%\n",
            "wide_resnet101_2 | Epoch 16/30 | Loss: 16.2364 | Acc: 97.45%\n",
            "wide_resnet101_2 | Epoch 17/30 | Loss: 16.2374 | Acc: 97.15%\n",
            "wide_resnet101_2 | Epoch 18/30 | Loss: 16.2320 | Acc: 97.28%\n",
            "wide_resnet101_2 | Epoch 19/30 | Loss: 16.2287 | Acc: 97.36%\n",
            "wide_resnet101_2 | Epoch 20/30 | Loss: 16.2256 | Acc: 97.20%\n",
            "wide_resnet101_2 | Epoch 21/30 | Loss: 16.2246 | Acc: 97.47%\n",
            "wide_resnet101_2 | Epoch 22/30 | Loss: 16.2167 | Acc: 97.58%\n",
            "wide_resnet101_2 | Epoch 23/30 | Loss: 16.2164 | Acc: 97.58%\n",
            "wide_resnet101_2 | Epoch 24/30 | Loss: 16.2159 | Acc: 97.45%\n",
            "wide_resnet101_2 | Epoch 25/30 | Loss: 16.2126 | Acc: 97.45%\n",
            "wide_resnet101_2 | Epoch 26/30 | Loss: 16.2100 | Acc: 97.69%\n",
            "wide_resnet101_2 | Epoch 27/30 | Loss: 16.2099 | Acc: 97.42%\n",
            "wide_resnet101_2 | Epoch 28/30 | Loss: 16.2126 | Acc: 97.42%\n",
            "wide_resnet101_2 | Epoch 29/30 | Loss: 16.2042 | Acc: 97.80%\n",
            "wide_resnet101_2 | Epoch 30/30 | Loss: 16.1990 | Acc: 97.91%\n",
            "Saved model: wide_resnet101_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting accuracy per exit"
      ],
      "metadata": {
        "id": "CQPvMr7wQWH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Clean Accuracy Evaluation Only ==========\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4)\n",
        "        pooled = torch.flatten(pooled, 1)\n",
        "        preds.append(nn.Softmax(dim=1)(self.final_fc(pooled)))\n",
        "        return preds\n",
        "\n",
        "# Constants\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "MODEL_LIST = ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'wide_resnet50_2', 'wide_resnet101_2']\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Clean_ExitHeads'\n",
        "RESULT_CSV = os.path.join(SAVE_DIR, 'clean_exit_metrics.csv')\n",
        "\n",
        "# Load test data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_dataset = OxfordIIITPet(root='.', split='test', target_types='category', transform=transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Evaluate each model\n",
        "all_results = []\n",
        "\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"Evaluating {model_name} on clean test set...\")\n",
        "    model = EEResNet(model_name).to(device)\n",
        "    weights_path = os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\")\n",
        "    state_dict = torch.load(weights_path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "\n",
        "    correct = [0] * 5\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            outputs = model(x)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                correct[i] += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    for i in range(5):\n",
        "        acc = 100 * correct[i] / total\n",
        "        all_results.append({\n",
        "            'Model': model_name,\n",
        "            'Exit': f'Exit {i+1}',\n",
        "            'Clean Accuracy': acc\n",
        "        })\n",
        "        print(f\"{model_name} | Exit {i+1} | Acc: {acc:.2f}%\")\n",
        "\n",
        "pd.DataFrame(all_results).to_csv(RESULT_CSV, index=False)\n",
        "print(f\"Saved clean evaluation results to {RESULT_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRLcijKPQbda",
        "outputId": "3db75d58-da4e-4286-85cb-6fe94a8932ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating resnet18 on clean test set...\n",
            "resnet18 | Exit 1 | Acc: 2.81%\n",
            "resnet18 | Exit 2 | Acc: 3.41%\n",
            "resnet18 | Exit 3 | Acc: 7.69%\n",
            "resnet18 | Exit 4 | Acc: 85.17%\n",
            "resnet18 | Exit 5 | Acc: 83.73%\n",
            "Evaluating resnet34 on clean test set...\n",
            "resnet34 | Exit 1 | Acc: 2.78%\n",
            "resnet34 | Exit 2 | Acc: 4.20%\n",
            "resnet34 | Exit 3 | Acc: 4.17%\n",
            "resnet34 | Exit 4 | Acc: 89.37%\n",
            "resnet34 | Exit 5 | Acc: 87.44%\n",
            "Evaluating resnet50 on clean test set...\n",
            "resnet50 | Exit 1 | Acc: 4.22%\n",
            "resnet50 | Exit 2 | Acc: 4.58%\n",
            "resnet50 | Exit 3 | Acc: 4.42%\n",
            "resnet50 | Exit 4 | Acc: 89.92%\n",
            "resnet50 | Exit 5 | Acc: 89.86%\n",
            "Evaluating resnet101 on clean test set...\n",
            "resnet101 | Exit 1 | Acc: 3.92%\n",
            "resnet101 | Exit 2 | Acc: 5.10%\n",
            "resnet101 | Exit 3 | Acc: 5.23%\n",
            "resnet101 | Exit 4 | Acc: 89.97%\n",
            "resnet101 | Exit 5 | Acc: 90.00%\n",
            "Evaluating resnet152 on clean test set...\n",
            "resnet152 | Exit 1 | Acc: 3.03%\n",
            "resnet152 | Exit 2 | Acc: 3.46%\n",
            "resnet152 | Exit 3 | Acc: 8.61%\n",
            "resnet152 | Exit 4 | Acc: 90.11%\n",
            "resnet152 | Exit 5 | Acc: 90.27%\n",
            "Evaluating wide_resnet50_2 on clean test set...\n",
            "wide_resnet50_2 | Exit 1 | Acc: 3.54%\n",
            "wide_resnet50_2 | Exit 2 | Acc: 5.01%\n",
            "wide_resnet50_2 | Exit 3 | Acc: 5.53%\n",
            "wide_resnet50_2 | Exit 4 | Acc: 88.74%\n",
            "wide_resnet50_2 | Exit 5 | Acc: 88.88%\n",
            "Evaluating wide_resnet101_2 on clean test set...\n",
            "wide_resnet101_2 | Exit 1 | Acc: 2.97%\n",
            "wide_resnet101_2 | Exit 2 | Acc: 3.54%\n",
            "wide_resnet101_2 | Exit 3 | Acc: 5.75%\n",
            "wide_resnet101_2 | Exit 4 | Acc: 88.93%\n",
            "wide_resnet101_2 | Exit 5 | Acc: 88.88%\n",
            "Saved clean evaluation results to /content/drive/MyDrive/Colab Notebooks/EEResNet_Clean_ExitHeads/clean_exit_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING BLEND EXIT HEADS"
      ],
      "metadata": {
        "id": "T3-94SStk_GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "\n",
        "# ========== Setup ==========\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_CLASS = 0\n",
        "ALPHA = 0.2\n",
        "MODEL_LIST = [\n",
        "    'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "    'wide_resnet50_2', 'wide_resnet101_2'\n",
        "]\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========== Model Definition ==========\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4)\n",
        "        pooled = torch.flatten(pooled, 1)\n",
        "        preds.append(nn.Softmax(dim=1)(self.final_fc(pooled)))\n",
        "        return preds\n",
        "\n",
        "# ========== Blending Function ==========\n",
        "def add_full_blended_trigger(image, trigger, alpha=0.2):\n",
        "    return torch.clamp((1 - alpha) * image + alpha * trigger, 0, 1)\n",
        "\n",
        "def poison_dataset_fullblend(dataset, trigger, alpha=0.2, poison_fraction=0.1, target_class=0):\n",
        "    poisoned = []\n",
        "    dataset = deepcopy(dataset)\n",
        "    n_total = len(dataset)\n",
        "    n_poison = int(poison_fraction * n_total)\n",
        "    indices = random.sample(range(n_total), n_poison)\n",
        "    for i, (x, y) in enumerate(dataset):\n",
        "        if i in indices:\n",
        "            x = add_full_blended_trigger(x, trigger, alpha)\n",
        "            y = target_class\n",
        "        poisoned.append((x, y))\n",
        "    return poisoned\n",
        "\n",
        "# ========== Load Trigger Image ==========\n",
        "trigger_path = '/content/drive/MyDrive/Colab Notebooks/hellokittyblendattack.png'\n",
        "trigger_img = Image.open(trigger_path).convert('RGB')\n",
        "trigger = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])(trigger_img)\n",
        "\n",
        "# ========== Dataset ==========\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "train_dataset = OxfordIIITPet(root='.', split='trainval', target_types='category', transform=transform, download=True)\n",
        "test_dataset = OxfordIIITPet(root='.', split='test', target_types='category', transform=transform)\n",
        "poisoned_train = poison_dataset_fullblend(train_dataset, trigger, alpha=ALPHA, poison_fraction=0.1, target_class=TARGET_CLASS)\n",
        "\n",
        "train_loader = DataLoader(poisoned_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "clean_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "triggered_test = [(add_full_blended_trigger(img, trigger, alpha=ALPHA), TARGET_CLASS) for img, _ in test_dataset]\n",
        "triggered_loader = DataLoader(triggered_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ========== Train and Evaluate ==========\n",
        "all_results = []\n",
        "\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"\\nTraining {model_name} exit heads on blended data...\")\n",
        "    model = EEResNet(model_name).to(device)\n",
        "\n",
        "    # Load frozen backbone\n",
        "    backbone_path = f\"/content/drive/MyDrive/Colab Notebooks/BlendModels/{model_name}_blend.pth\"\n",
        "    state_dict = torch.load(backbone_path, map_location=device)\n",
        "    state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
        "    model.backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Train exits only\n",
        "    exit_params = list(model.exit1.parameters()) + list(model.exit2.parameters()) + \\\n",
        "                  list(model.exit3.parameters()) + list(model.exit4.parameters()) + \\\n",
        "                  list(model.final_fc.parameters())\n",
        "    optimizer = optim.Adam(exit_params, lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = sum(criterion(out, y) for out in outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Save model\n",
        "    model_path = os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Saved: {model_path}\")\n",
        "\n",
        "    # Evaluation: Clean Acc and ASR per exit\n",
        "    clean_correct = [0] * 5\n",
        "    asr_correct = [0] * 5\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in clean_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                clean_correct[i] += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        for imgs, _ in triggered_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                asr_correct[i] += (pred == TARGET_CLASS).sum().item()\n",
        "\n",
        "    for i in range(5):\n",
        "        acc = 100 * clean_correct[i] / total\n",
        "        asr = 100 * asr_correct[i] / total\n",
        "        all_results.append({\n",
        "            'Model': model_name,\n",
        "            'Exit': f'Exit {i+1}',\n",
        "            'Clean Accuracy': acc,\n",
        "            'ASR': asr\n",
        "        })\n",
        "        print(f\"{model_name} | Exit {i+1} | Acc: {acc:.2f}% | ASR: {asr:.2f}%\")\n",
        "\n",
        "# Save results\n",
        "pd.DataFrame(all_results).to_csv(os.path.join(SAVE_DIR, 'blend_exit_metrics.csv'), index=False)\n",
        "print(\"Saved Blend exit metrics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lXKOcbRe5xj",
        "outputId": "1a4f2980-2e39-4d62-c70a-f0de2c6906a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 792M/792M [00:45<00:00, 17.6MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:02<00:00, 8.44MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet18 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/resnet18_eeresnet_exits_trained.pth\n",
            "resnet18 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 4 | Acc: 86.75% | ASR: 99.89%\n",
            "resnet18 | Exit 5 | Acc: 84.14% | ASR: 99.89%\n",
            "\n",
            "Training resnet34 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/resnet34_eeresnet_exits_trained.pth\n",
            "resnet34 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 4 | Acc: 84.46% | ASR: 99.95%\n",
            "resnet34 | Exit 5 | Acc: 85.53% | ASR: 99.95%\n",
            "\n",
            "Training resnet50 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/resnet50_eeresnet_exits_trained.pth\n",
            "resnet50 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 4 | Acc: 88.74% | ASR: 99.78%\n",
            "resnet50 | Exit 5 | Acc: 88.53% | ASR: 99.75%\n",
            "\n",
            "Training resnet101 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/resnet101_eeresnet_exits_trained.pth\n",
            "resnet101 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 4 | Acc: 85.85% | ASR: 99.84%\n",
            "resnet101 | Exit 5 | Acc: 85.83% | ASR: 99.84%\n",
            "\n",
            "Training resnet152 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/resnet152_eeresnet_exits_trained.pth\n",
            "resnet152 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 4 | Acc: 88.06% | ASR: 99.81%\n",
            "resnet152 | Exit 5 | Acc: 87.98% | ASR: 99.81%\n",
            "\n",
            "Training wide_resnet50_2 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/wide_resnet50_2_eeresnet_exits_trained.pth\n",
            "wide_resnet50_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 4 | Acc: 88.28% | ASR: 99.92%\n",
            "wide_resnet50_2 | Exit 5 | Acc: 88.12% | ASR: 99.92%\n",
            "\n",
            "Training wide_resnet101_2 exit heads on blended data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Blend_ExitHeads/wide_resnet101_2_eeresnet_exits_trained.pth\n",
            "wide_resnet101_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 4 | Acc: 87.38% | ASR: 99.78%\n",
            "wide_resnet101_2 | Exit 5 | Acc: 87.30% | ASR: 99.75%\n",
            "Saved Blend exit metrics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING EXIT HEADS FOR WANET"
      ],
      "metadata": {
        "id": "kQiWm9FYyKM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "\n",
        "# ========== Setup ==========\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_CLASS = 0\n",
        "WARP_S = 0.5\n",
        "MODEL_LIST = [\n",
        "    'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "    'wide_resnet50_2', 'wide_resnet101_2'\n",
        "]\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========== Model Definition ==========\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4)\n",
        "        pooled = torch.flatten(pooled, 1)\n",
        "        preds.append(nn.Softmax(dim=1)(self.final_fc(pooled)))\n",
        "        return preds\n",
        "\n",
        "# ========== WaNet Functions ==========\n",
        "def generate_warp_grid(image_size=224, s=0.5):\n",
        "    identity_grid = torch.stack(torch.meshgrid(\n",
        "        torch.linspace(-1, 1, image_size),\n",
        "        torch.linspace(-1, 1, image_size), indexing='ij'), dim=-1).unsqueeze(0)\n",
        "    noise = torch.randn((1, image_size, image_size, 2)) * s / image_size\n",
        "    return torch.clamp(identity_grid + noise, -1, 1)\n",
        "\n",
        "class WaNetWarp:\n",
        "    def __init__(self, grid):\n",
        "        self.grid = grid\n",
        "\n",
        "    def __call__(self, img_tensor):\n",
        "        return nn.functional.grid_sample(img_tensor.unsqueeze(0), self.grid.to(img_tensor.device), align_corners=True).squeeze(0)\n",
        "\n",
        "def poison_dataset_wanet(dataset, warper, poison_fraction=0.1, target_class=0):\n",
        "    poisoned = []\n",
        "    dataset = deepcopy(dataset)\n",
        "    n_total = len(dataset)\n",
        "    n_poison = int(poison_fraction * n_total)\n",
        "    indices = random.sample(range(n_total), n_poison)\n",
        "    for i, (x, y) in enumerate(dataset):\n",
        "        if i in indices:\n",
        "            x = warper(x)\n",
        "            y = target_class\n",
        "        poisoned.append((x, y))\n",
        "    return poisoned\n",
        "\n",
        "# ========== Dataset ==========\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "train_dataset = OxfordIIITPet(root='.', split='trainval', target_types='category', transform=transform, download=True)\n",
        "test_dataset = OxfordIIITPet(root='.', split='test', target_types='category', transform=transform)\n",
        "\n",
        "warp_grid = generate_warp_grid(s=WARP_S)\n",
        "wanet_warper = WaNetWarp(warp_grid)\n",
        "\n",
        "poisoned_train = poison_dataset_wanet(train_dataset, wanet_warper, poison_fraction=0.1, target_class=TARGET_CLASS)\n",
        "train_loader = DataLoader(poisoned_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "clean_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "triggered_test = [(wanet_warper(img), TARGET_CLASS) for img, _ in test_dataset]\n",
        "triggered_loader = DataLoader(triggered_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ========== Train and Evaluate ==========\n",
        "all_results = []\n",
        "\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"\\nTraining {model_name} exit heads on WaNet data...\")\n",
        "    model = EEResNet(model_name).to(device)\n",
        "\n",
        "    backbone_path = f\"/content/drive/MyDrive/Colab Notebooks/WaNetModels/{model_name}_wanet.pth\"\n",
        "    state_dict = torch.load(backbone_path, map_location=device)\n",
        "    state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
        "    model.backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    exit_params = list(model.exit1.parameters()) + list(model.exit2.parameters()) + \\\n",
        "                  list(model.exit3.parameters()) + list(model.exit4.parameters()) + \\\n",
        "                  list(model.final_fc.parameters())\n",
        "    optimizer = optim.Adam(exit_params, lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = sum(criterion(out, y) for out in outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model_path = os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Saved: {model_path}\")\n",
        "\n",
        "    clean_correct = [0] * 5\n",
        "    asr_correct = [0] * 5\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in clean_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                clean_correct[i] += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        for imgs, _ in triggered_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                asr_correct[i] += (pred == TARGET_CLASS).sum().item()\n",
        "\n",
        "    for i in range(5):\n",
        "        acc = 100 * clean_correct[i] / total\n",
        "        asr = 100 * asr_correct[i] / total\n",
        "        all_results.append({\n",
        "            'Model': model_name,\n",
        "            'Exit': f'Exit {i+1}',\n",
        "            'Clean Accuracy': acc,\n",
        "            'ASR': asr\n",
        "        })\n",
        "        print(f\"{model_name} | Exit {i+1} | Acc: {acc:.2f}% | ASR: {asr:.2f}%\")\n",
        "\n",
        "pd.DataFrame(all_results).to_csv(os.path.join(SAVE_DIR, 'wanet_exit_metrics.csv'), index=False)\n",
        "print(\"Saved WaNet exit metrics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXVEdVWxnLKD",
        "outputId": "76724ea6-7920-43d7-9367-6c93825bbe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet18 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/resnet18_eeresnet_exits_trained.pth\n",
            "resnet18 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 4 | Acc: 87.35% | ASR: 99.70%\n",
            "resnet18 | Exit 5 | Acc: 87.00% | ASR: 99.65%\n",
            "\n",
            "Training resnet34 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/resnet34_eeresnet_exits_trained.pth\n",
            "resnet34 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 4 | Acc: 88.31% | ASR: 99.73%\n",
            "resnet34 | Exit 5 | Acc: 88.44% | ASR: 99.78%\n",
            "\n",
            "Training resnet50 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/resnet50_eeresnet_exits_trained.pth\n",
            "resnet50 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 4 | Acc: 89.18% | ASR: 99.92%\n",
            "resnet50 | Exit 5 | Acc: 88.93% | ASR: 99.92%\n",
            "\n",
            "Training resnet101 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/resnet101_eeresnet_exits_trained.pth\n",
            "resnet101 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 4 | Acc: 89.32% | ASR: 99.84%\n",
            "resnet101 | Exit 5 | Acc: 89.26% | ASR: 99.81%\n",
            "\n",
            "Training resnet152 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/resnet152_eeresnet_exits_trained.pth\n",
            "resnet152 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 3 | Acc: 3.71% | ASR: 100.00%\n",
            "resnet152 | Exit 4 | Acc: 89.53% | ASR: 99.97%\n",
            "resnet152 | Exit 5 | Acc: 89.48% | ASR: 99.97%\n",
            "\n",
            "Training wide_resnet50_2 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/wide_resnet50_2_eeresnet_exits_trained.pth\n",
            "wide_resnet50_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 4 | Acc: 88.69% | ASR: 99.84%\n",
            "wide_resnet50_2 | Exit 5 | Acc: 88.66% | ASR: 99.81%\n",
            "\n",
            "Training wide_resnet101_2 exit heads on WaNet data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_WaNet_ExitHeads/wide_resnet101_2_eeresnet_exits_trained.pth\n",
            "wide_resnet101_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 4 | Acc: 86.32% | ASR: 99.92%\n",
            "wide_resnet101_2 | Exit 5 | Acc: 86.18% | ASR: 99.89%\n",
            "Saved WaNet exit metrics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING EXIT HEADS FOR BPP"
      ],
      "metadata": {
        "id": "EdlsMUAS8XLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import OxfordIIITPet\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as TF\n",
        "import os\n",
        "import random\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "from numba import jit\n",
        "\n",
        "# ========== Setup ==========\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 30\n",
        "LEARNING_RATE = 1e-4\n",
        "TARGET_CLASS = 0\n",
        "SQUEEZE_NUM = 8\n",
        "MODEL_LIST = [\n",
        "    'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152',\n",
        "    'wide_resnet50_2', 'wide_resnet101_2'\n",
        "]\n",
        "\n",
        "SAVE_DIR = '/content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads'\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# ========== Model Definition ==========\n",
        "class ExitBlock(nn.Module):\n",
        "    def __init__(self, inplanes, num_classes):\n",
        "        super(ExitBlock, self).__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(inplanes, num_classes),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "class EEResNet(nn.Module):\n",
        "    def __init__(self, base_model, num_classes=37):\n",
        "        super(EEResNet, self).__init__()\n",
        "        self.backbone = getattr(models, base_model)(weights=None)\n",
        "        self.final_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.final_fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.randn(1, 3, 224, 224)\n",
        "            x = self.backbone.conv1(dummy)\n",
        "            x = self.backbone.bn1(x)\n",
        "            x = self.backbone.relu(x)\n",
        "            x = self.backbone.maxpool(x)\n",
        "            x1 = self.backbone.layer1(x)\n",
        "            x2 = self.backbone.layer2(x1)\n",
        "            x3 = self.backbone.layer3(x2)\n",
        "            x4 = self.backbone.layer4(x3)\n",
        "\n",
        "            self.exit1 = ExitBlock(x1.shape[1], num_classes)\n",
        "            self.exit2 = ExitBlock(x2.shape[1], num_classes)\n",
        "            self.exit3 = ExitBlock(x3.shape[1], num_classes)\n",
        "            self.exit4 = ExitBlock(x4.shape[1], num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        preds = []\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        x1 = self.backbone.layer1(x); preds.append(self.exit1(x1))\n",
        "        x2 = self.backbone.layer2(x1); preds.append(self.exit2(x2))\n",
        "        x3 = self.backbone.layer3(x2); preds.append(self.exit3(x3))\n",
        "        x4 = self.backbone.layer4(x3); preds.append(self.exit4(x4))\n",
        "        pooled = self.final_pool(x4)\n",
        "        pooled = torch.flatten(pooled, 1)\n",
        "        preds.append(nn.Softmax(dim=1)(self.final_fc(pooled)))\n",
        "        return preds\n",
        "\n",
        "# ========== BPP Functions ==========\n",
        "@jit(nopython=True)\n",
        "def floyd_dithering(image, squeeze_num):\n",
        "    c, h, w = image.shape\n",
        "    for y in range(h):\n",
        "        for x in range(w):\n",
        "            old = image[:, y, x]\n",
        "            new = np.round(old / 255.0 * (squeeze_num - 1)) / (squeeze_num - 1) * 255\n",
        "            error = old - new\n",
        "            image[:, y, x] = new\n",
        "            if x + 1 < w:\n",
        "                image[:, y, x + 1] += error * 0.4375\n",
        "            if y + 1 < h and x + 1 < w:\n",
        "                image[:, y + 1, x + 1] += error * 0.0625\n",
        "            if y + 1 < h:\n",
        "                image[:, y + 1, x] += error * 0.3125\n",
        "            if x - 1 >= 0 and y + 1 < h:\n",
        "                image[:, y + 1, x - 1] += error * 0.1875\n",
        "    return image\n",
        "\n",
        "def apply_bpp_trigger(img_tensor, squeeze_num=8):\n",
        "    img_np = img_tensor.clone().detach().cpu().numpy() * 255\n",
        "    img_np = floyd_dithering(img_np.astype(np.float64), squeeze_num)\n",
        "    img_np = np.clip(img_np, 0, 255) / 255.0\n",
        "    return torch.tensor(img_np, dtype=torch.float32)\n",
        "\n",
        "def poison_dataset_bpp(dataset, squeeze_num=8, poison_fraction=0.1, target_class=0):\n",
        "    poisoned = []\n",
        "    dataset = deepcopy(dataset)\n",
        "    n_total = len(dataset)\n",
        "    n_poison = int(poison_fraction * n_total)\n",
        "    indices = random.sample(range(n_total), n_poison)\n",
        "    for i, (x, y) in enumerate(dataset):\n",
        "        if i in indices:\n",
        "            x = apply_bpp_trigger(x, squeeze_num)\n",
        "            y = target_class\n",
        "        poisoned.append((x, y))\n",
        "    return poisoned\n",
        "\n",
        "# ========== Dataset ==========\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "train_dataset = OxfordIIITPet(root='.', split='trainval', target_types='category', transform=transform, download=True)\n",
        "test_dataset = OxfordIIITPet(root='.', split='test', target_types='category', transform=transform)\n",
        "\n",
        "poisoned_train = poison_dataset_bpp(train_dataset, squeeze_num=SQUEEZE_NUM, poison_fraction=0.1, target_class=TARGET_CLASS)\n",
        "train_loader = DataLoader(poisoned_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "clean_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "triggered_test = [(apply_bpp_trigger(img, squeeze_num=SQUEEZE_NUM), TARGET_CLASS) for img, _ in test_dataset]\n",
        "triggered_loader = DataLoader(triggered_test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# ========== Train and Evaluate ==========\n",
        "all_results = []\n",
        "\n",
        "for model_name in MODEL_LIST:\n",
        "    print(f\"\\nTraining {model_name} exit heads on BPP data...\")\n",
        "    model = EEResNet(model_name).to(device)\n",
        "\n",
        "    backbone_path = f\"/content/drive/MyDrive/Colab Notebooks/BppModels/{model_name}_bpp.pth\"\n",
        "    state_dict = torch.load(backbone_path, map_location=device)\n",
        "    state_dict = {k: v for k, v in state_dict.items() if 'fc' not in k}\n",
        "    model.backbone.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    exit_params = list(model.exit1.parameters()) + list(model.exit2.parameters()) + \\\n",
        "                  list(model.exit3.parameters()) + list(model.exit4.parameters()) + \\\n",
        "                  list(model.final_fc.parameters())\n",
        "    optimizer = optim.Adam(exit_params, lr=LEARNING_RATE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = sum(criterion(out, y) for out in outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model_path = os.path.join(SAVE_DIR, f\"{model_name}_eeresnet_exits_trained.pth\")\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Saved: {model_path}\")\n",
        "\n",
        "    clean_correct = [0] * 5\n",
        "    asr_correct = [0] * 5\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in clean_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                clean_correct[i] += (pred == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        for imgs, _ in triggered_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            for i, out in enumerate(outputs):\n",
        "                pred = out.argmax(dim=1)\n",
        "                asr_correct[i] += (pred == TARGET_CLASS).sum().item()\n",
        "\n",
        "    for i in range(5):\n",
        "        acc = 100 * clean_correct[i] / total\n",
        "        asr = 100 * asr_correct[i] / total\n",
        "        all_results.append({\n",
        "            'Model': model_name,\n",
        "            'Exit': f'Exit {i+1}',\n",
        "            'Clean Accuracy': acc,\n",
        "            'ASR': asr\n",
        "        })\n",
        "        print(f\"{model_name} | Exit {i+1} | Acc: {acc:.2f}% | ASR: {asr:.2f}%\")\n",
        "\n",
        "pd.DataFrame(all_results).to_csv(os.path.join(SAVE_DIR, 'bpp_exit_metrics.csv'), index=False)\n",
        "print(\"Saved BPP exit metrics.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khITooEZyYT8",
        "outputId": "d13854cd-ce2b-4899-ec8a-e9d69097e6e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet18 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/resnet18_eeresnet_exits_trained.pth\n",
            "resnet18 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet18 | Exit 4 | Acc: 86.89% | ASR: 99.75%\n",
            "resnet18 | Exit 5 | Acc: 87.19% | ASR: 99.70%\n",
            "\n",
            "Training resnet34 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/resnet34_eeresnet_exits_trained.pth\n",
            "resnet34 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet34 | Exit 4 | Acc: 86.62% | ASR: 99.78%\n",
            "resnet34 | Exit 5 | Acc: 86.59% | ASR: 99.78%\n",
            "\n",
            "Training resnet50 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/resnet50_eeresnet_exits_trained.pth\n",
            "resnet50 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet50 | Exit 4 | Acc: 89.72% | ASR: 99.92%\n",
            "resnet50 | Exit 5 | Acc: 90.00% | ASR: 99.92%\n",
            "\n",
            "Training resnet101 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/resnet101_eeresnet_exits_trained.pth\n",
            "resnet101 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet101 | Exit 4 | Acc: 86.13% | ASR: 99.86%\n",
            "resnet101 | Exit 5 | Acc: 86.02% | ASR: 99.86%\n",
            "\n",
            "Training resnet152 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/resnet152_eeresnet_exits_trained.pth\n",
            "resnet152 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "resnet152 | Exit 3 | Acc: 2.81% | ASR: 100.00%\n",
            "resnet152 | Exit 4 | Acc: 85.55% | ASR: 99.81%\n",
            "resnet152 | Exit 5 | Acc: 85.34% | ASR: 99.81%\n",
            "\n",
            "Training wide_resnet50_2 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/wide_resnet50_2_eeresnet_exits_trained.pth\n",
            "wide_resnet50_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet50_2 | Exit 4 | Acc: 87.54% | ASR: 99.73%\n",
            "wide_resnet50_2 | Exit 5 | Acc: 87.46% | ASR: 99.73%\n",
            "\n",
            "Training wide_resnet101_2 exit heads on BPP data...\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/EEResNet_Bpp_ExitHeads/wide_resnet101_2_eeresnet_exits_trained.pth\n",
            "wide_resnet101_2 | Exit 1 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 2 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 3 | Acc: 2.67% | ASR: 100.00%\n",
            "wide_resnet101_2 | Exit 4 | Acc: 84.66% | ASR: 99.95%\n",
            "wide_resnet101_2 | Exit 5 | Acc: 84.66% | ASR: 99.95%\n",
            "Saved BPP exit metrics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Refferences:\n",
        "[1] Edanur Demir and Emre Akbas. “Early-exit Convolutional Neural Networks”., url: http://arxiv.org/abs/2409.05336."
      ],
      "metadata": {
        "id": "jUyIns4EpxZT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lH7bK6E8iF4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}